{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Frequency Trading Algorithm\n",
    "\n",
    "You have been tasked by the investment firm Renaissance High Frequency Trading (RHFT) to develop an automated trading strategy utilizing a combination of machine learning algorithms and high frequency algorithms. RHFT wants this new algorithm to be based on stock market data of the 30 stocks in the Dow Jones at the minute level and to conduct buys and sells every minute based on 1 min, 5 min, and 10 min Momentum. The CIO asked you to choose the Machine Learning Algorithm best suited for this task and wants you to execute the trades via Alpaca's API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Prepare the data for training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "import alpaca_trade_api as tradeapi\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load .env enviroment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Alpaca API key and secret\n",
    "API_KEY = os.getenv(\"ALPACA_API_KEY\")\n",
    "API_SECRET = os.getenv(\"ALPACA_SECRET_KEY\")\n",
    "ALPACA_API_BASE_URL = \"https://paper-api.alpaca.markets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpaca Key type: <class 'str'>\n",
      "Alpaca Secret Key type: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Alpaca Key type: {type(API_KEY)}\")\n",
    "print(f\"Alpaca Secret Key type: {type(API_SECRET)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Alpaca API object, specifying use of the paper trading account:\n",
    "api = tradeapi.REST(API_KEY, API_SECRET, ALPACA_API_BASE_URL, api_version='v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create a ticker list, beginning and end dates, and timeframe interval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of tickers\n",
    "ticker_list = [\"TSLA\", \"MSFT\", \"AMZN\", \"FB\", \"AAPL\", \"NVDA\", \"GOOG\", \"CRM\"]\n",
    "\n",
    "# declare begin and end date strings\n",
    "beg_date = '2022-05-27'\n",
    "end_date = '2022-05-27'\n",
    "# we convert begin and end date to formats that the ALPACA API requires\n",
    "start =  pd.Timestamp(f'{beg_date} 09:30:00-0400', tz='America/New_York').replace(hour=9, minute=30, second=0).astimezone('GMT').isoformat()[:-6]+'Z'\n",
    "end   =  pd.Timestamp(f'{end_date} 16:00:00-0400', tz='America/New_York').replace(hour=16, minute=0, second=0).astimezone('GMT').isoformat()[:-6]+'Z'\n",
    "# We set the time frequency at which we want to pull prices\n",
    "timeframe='1Min'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Ping the Alpaca API for the data and store it in a DataFrame called `prices` by using the `get_barset` function combined with the `df` method from the Alpaca Trade SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull prices from the ALPACA API\n",
    "prices = api.get_bars(ticker_list, timeframe, limit=1000, start=start, end=end).df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>trade_count</th>\n",
       "      <th>vwap</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-05-27 13:30:00+00:00</th>\n",
       "      <td>145.39</td>\n",
       "      <td>145.740</td>\n",
       "      <td>145.260</td>\n",
       "      <td>145.540</td>\n",
       "      <td>1718145</td>\n",
       "      <td>16997</td>\n",
       "      <td>145.401780</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-27 13:31:00+00:00</th>\n",
       "      <td>145.56</td>\n",
       "      <td>146.130</td>\n",
       "      <td>145.560</td>\n",
       "      <td>146.000</td>\n",
       "      <td>656681</td>\n",
       "      <td>5929</td>\n",
       "      <td>145.872124</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-27 13:32:00+00:00</th>\n",
       "      <td>146.00</td>\n",
       "      <td>146.230</td>\n",
       "      <td>145.930</td>\n",
       "      <td>146.180</td>\n",
       "      <td>411564</td>\n",
       "      <td>3584</td>\n",
       "      <td>146.068032</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-27 13:33:00+00:00</th>\n",
       "      <td>146.18</td>\n",
       "      <td>146.205</td>\n",
       "      <td>146.020</td>\n",
       "      <td>146.045</td>\n",
       "      <td>374322</td>\n",
       "      <td>3481</td>\n",
       "      <td>146.121218</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-27 13:34:00+00:00</th>\n",
       "      <td>146.04</td>\n",
       "      <td>146.110</td>\n",
       "      <td>145.751</td>\n",
       "      <td>145.790</td>\n",
       "      <td>505251</td>\n",
       "      <td>3876</td>\n",
       "      <td>145.933648</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             open     high      low    close   volume  \\\n",
       "timestamp                                                               \n",
       "2022-05-27 13:30:00+00:00  145.39  145.740  145.260  145.540  1718145   \n",
       "2022-05-27 13:31:00+00:00  145.56  146.130  145.560  146.000   656681   \n",
       "2022-05-27 13:32:00+00:00  146.00  146.230  145.930  146.180   411564   \n",
       "2022-05-27 13:33:00+00:00  146.18  146.205  146.020  146.045   374322   \n",
       "2022-05-27 13:34:00+00:00  146.04  146.110  145.751  145.790   505251   \n",
       "\n",
       "                           trade_count        vwap symbol  \n",
       "timestamp                                                  \n",
       "2022-05-27 13:30:00+00:00        16997  145.401780   AAPL  \n",
       "2022-05-27 13:31:00+00:00         5929  145.872124   AAPL  \n",
       "2022-05-27 13:32:00+00:00         3584  146.068032   AAPL  \n",
       "2022-05-27 13:33:00+00:00         3481  146.121218   AAPL  \n",
       "2022-05-27 13:34:00+00:00         3876  145.933648   AAPL  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Store only the close prices from the `prices` DataFrame in a new DataFrame called `df_closing_prices`, then view the head and tail to confirm the following:\n",
    "* First price for each stock on the open at 9:30 Eastern Time.\n",
    "* Last price for the day on the close at 3:59 pm Eastern Time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame for closing prices\n",
    "df_closing_prices = pd.DataFrame()\n",
    "\n",
    "# Fetch the closing prices for each one of the tickers and store in a column in df_closing_prices amed after that ticker\n",
    "for ticker in ticker_list:\n",
    "    df_closing_prices[ticker] = prices.loc[prices['symbol'] == ticker]['close']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSLA</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>FB</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>NVDA</th>\n",
       "      <th>GOOG</th>\n",
       "      <th>CRM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-05-27 13:30:00+00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2271.970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>161.0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-27 13:31:00+00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2281.460</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.6900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-27 13:32:00+00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2280.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146.180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.9900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-27 13:33:00+00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2271.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146.045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>161.1150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-27 13:34:00+00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2264.365</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>161.0900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           TSLA  MSFT      AMZN  FB     AAPL  NVDA  GOOG  \\\n",
       "timestamp                                                                  \n",
       "2022-05-27 13:30:00+00:00   NaN   NaN  2271.970 NaN  145.540   NaN   NaN   \n",
       "2022-05-27 13:31:00+00:00   NaN   NaN  2281.460 NaN  146.000   NaN   NaN   \n",
       "2022-05-27 13:32:00+00:00   NaN   NaN  2280.750 NaN  146.180   NaN   NaN   \n",
       "2022-05-27 13:33:00+00:00   NaN   NaN  2271.010 NaN  146.045   NaN   NaN   \n",
       "2022-05-27 13:34:00+00:00   NaN   NaN  2264.365 NaN  145.790   NaN   NaN   \n",
       "\n",
       "                                CRM  \n",
       "timestamp                            \n",
       "2022-05-27 13:30:00+00:00  161.0025  \n",
       "2022-05-27 13:31:00+00:00  160.6900  \n",
       "2022-05-27 13:32:00+00:00  160.9900  \n",
       "2022-05-27 13:33:00+00:00  161.1150  \n",
       "2022-05-27 13:34:00+00:00  161.0900  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview first five rows\n",
    "df_closing_prices.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSLA</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>FB</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>NVDA</th>\n",
       "      <th>GOOG</th>\n",
       "      <th>CRM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-05-27 19:56:00+00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2299.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149.195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-27 19:57:00+00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2299.46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149.415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-27 19:58:00+00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2299.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149.510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-27 19:59:00+00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2303.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149.650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-27 20:00:00+00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2301.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149.640</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           TSLA  MSFT     AMZN  FB     AAPL  NVDA  GOOG  CRM\n",
       "timestamp                                                                   \n",
       "2022-05-27 19:56:00+00:00   NaN   NaN  2299.99 NaN  149.195   NaN   NaN  NaN\n",
       "2022-05-27 19:57:00+00:00   NaN   NaN  2299.46 NaN  149.415   NaN   NaN  NaN\n",
       "2022-05-27 19:58:00+00:00   NaN   NaN  2299.88 NaN  149.510   NaN   NaN  NaN\n",
       "2022-05-27 19:59:00+00:00   NaN   NaN  2303.38 NaN  149.650   NaN   NaN  NaN\n",
       "2022-05-27 20:00:00+00:00   NaN   NaN  2301.99 NaN  149.640   NaN   NaN  NaN"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview last five rows\n",
    "df_closing_prices.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(390, 8)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of rows\n",
    "df_closing_prices.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. When viewing the head and tail, you'll notice several `NaN` values.\n",
    "* Alpaca reports `NaN` for minutes without any trades occuring as missing.\n",
    "* These values must be removed, we use Panda's `ffill()` function to \"forward fill\", or replace, those prices with the previous values (since the price has not changed).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Pandas' forward fill function to fill missing values (be sure to set inplace=True)\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Compute the percentage change values for 1 minute as follows:\n",
    "* Create a variable called `forecast` to hold the forecast, in this case `1` for 1 minute.\n",
    "* Use the `pct_change` function, passing in the `forecast`, on the `df_closing_prices` DataFrame, storeing the newly generated DataFrame in a variable called `returns`.\n",
    "* Convert the `returns` DataFrame to show forward returns by passing `-(forecast)` into the `shift function.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a variable to set prediction period\n",
    "# YOUR CODE HERE\n",
    "# Compute the pct_change for 1 min \n",
    "# YOUR CODE HERE\n",
    "# Shift the returns to convert them to forward returns\n",
    "# YOUR CODE HERE\n",
    "# Preview the DataFrame\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note: \n",
    "> You can verify these returns are computed correctly by analyzing the first observation for Facebook:\n",
    "> * 9:30 am for 0.000632.\n",
    " \n",
    "> How is that number computed? \n",
    " \n",
    "> * The price of Facebook at 9:30 is 269.00\n",
    "> * The price of Facebook at 9:31 is 269.17\n",
    "\n",
    "> Which gives you:\n",
    "\n",
    "> * (269.17 - \t269.00)/ 269.90 = 0.000632\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Convert the DataFrame into long form for merging later using `unstack` and `reset_index`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use unstack() to bring the data in long format and save the output as as dataframe\n",
    "# YOUR CODE HERE\n",
    "# Rename the column to make it easer to identify it:\n",
    "name = f'F_{forecast}_m_returns'\n",
    "returns.rename(columns={0: name}, inplace = True)\n",
    "# Reset the index of the dataframe for merging later (be sure to set inplace=True)\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the first five rows\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the last five rows\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Compute the 1, 5, 10 minute momentums that will be used to predict the forward returns, then merge them with the forward returns as follows:\n",
    "* Create the list of moments: `list_of_momentums = [1,5,10]`.\n",
    "* Write a for-loop to loop through the `list_of_momentums`, applying them to `pct_change` with the `df_closing_price` with each iteration.\n",
    "* With each loop, the data temporary DataFrame, `returns_temp` will need to be prepped with `unstack` and `reset_index`, then added as a new column to the original `returns` DataFrame from the prior step.\n",
    "* Complete this step by dropping the null values from `returns` and creating a multi-index based on date and ticker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of momentums that we want to predict\n",
    "list_of_momentums = [1,5,10]\n",
    "for i in list_of_momentums:   \n",
    "    # Compute percentage change for each one of the momentums in the momentum list\n",
    "    # YOUR CODE HERE\n",
    "    # Unstack the returns and save the output as as dataframe called returns_temp \n",
    "    # YOUR CODE HERE\n",
    "    # Rename the column to make it easer to identify it:\n",
    "    # YOUR CODE HERE\n",
    "    # Reset the index so we can merge based on index\n",
    "    # YOUR CODE HERE\n",
    "    # Merge returns_temp  with the original returns \n",
    "    returns = pd.merge(returns,returns_temp,left_on=['level_0', 'time'],right_on=['level_0', 'time'], how='left', suffixes=('_original', 'right'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use dropna() to get rid of those missing observations.\n",
    "# YOUR CODE HERE\n",
    "# Create a multi index based on level_0 and time\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Train and Compare Multiple Machine Learning Algorithms\n",
    "\n",
    " In this section, you'll train each of the requested algorithms and compare performance. Be sure to use the same parameters and training steps for each model. This is necessary to compare each model accurately.\n",
    "\n",
    "### Preprocessing Data\n",
    "\n",
    "#### 1. Generate your feature data (`X`) and target data (`y`):\n",
    "* Create a dataframe `X` that contains all the columns from the returns dataframe that will be used to predict `F_1_m_returns`.\n",
    "* Create a variable, called `y`, that is equal 1 if `F_1_m_returns` is larger than 0. This will be our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset returns.csv and set the index to level_0 and time\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a separate dataframe for features and define the target variable as a binary target\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Create the target variable\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note:\n",
    "> Notice that we don't use shuffle when splitting the dataset into a training and testing dataset. \n",
    "\n",
    "> We want to keep the original ordering of the data, so we don't end up using observations in the future to predict past observations,\n",
    "\n",
    "> This is a critical mistake known as look ahead bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Use the train_test_split library to split the dataset into a training and testing dataset, with 70% used for testing\n",
    "* Set the shuffle parameter to False, so that you use the first 70% for training to prvent look ahead bias.\n",
    "* Make sure you have these 4 variables: `X_train`, `X_test`, `y_train`, `y_test`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset without shuffling\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Use the `Counter` function to test the distribution of the data. \n",
    "* The result of `Counter({1: 668, 0: 1194})` reveals the data is indeed unbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Counter function from the collections library\n",
    "from collections import Counter\n",
    "\n",
    "# Use Counter to count the number 1s and 0 in y_train\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Balance the dataset with the Oversampler libary, setting `random state= 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RandomOverSampler from the imblearn library\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Use RandomOverSampler to resample the datase using random_state=1\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Test the distribution once again with `Counter`. The new result of `Counter({1: 1194, 0: 1194})` shows the data is now balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Counter again to verify imbalance removed\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "#### 1. The first cells in this section provide an example of how to fit and train your model using the `LogisticRegression` model from sklearn:\n",
    "* Import select model.\n",
    "* Instantiate model object.\n",
    "* Fit the model to the resampled data - `X_resampled` and `y_resampled`.\n",
    "* Predict the model using `X_test`.\n",
    "* Print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import classification_report from sklearn\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LogisticRegression from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create a LogisticRegression model and train it on the X_resampled data we created before\n",
    "log_model = LogisticRegression()\n",
    "log_model.fit(X_resampled, y_resampled)  \n",
    "\n",
    "# Use the model you trained to predict using X_test\n",
    "y_pred = log_model.predict(X_test)   \n",
    "\n",
    "# Print out a classification report toevaluate performance\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Use the same approach as above to train and test the following ML Algorithms:\n",
    "* [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "* [GradientBoostingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)\n",
    "* [AdaBoostClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html)\n",
    "* [XGBClassifier](https://xgboost.readthedocs.io/en/latest/python/python_api.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RandomForestClassifier from sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a RandomForestClassifier model and train it on the X_resampled data we created before\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Use the model you trained to predict using X_test\n",
    "# YOUR CODE HERE  \n",
    "\n",
    "# Print out a classification report to evaluate performance\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RandomForestClassifier from sklearn\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Create a GradientBoostingClassifier model and train it on the X_resampled data we created before\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Use the model you trained to predict using X_test\n",
    "# YOUR CODE HERE     \n",
    "\n",
    "# Print out a classification report to evaluate performance\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RandomForestClassifier from sklearn\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Create a AdaBoostClassifier model and train it on the X_resampled data we created before\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Use the model you trained to predict using X_test\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Print out a classification report to evaluate performance\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RandomForestClassifier from sklearn\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Create a XGBClassifier model and train it on the X_resampled data we created before\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Use the model you trained to predict using X_test\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Print out a classification report to evaluate performance\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the performance of each model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Using the classification report for each model, choose the model with the highest precision for use in your algo-trading program.\n",
    "#### 2. Save the selected model with the `joblib` libary to avoid retraining every time you wish to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the joblib library \n",
    "import joblib\n",
    "\n",
    "# Use the library to save the model that you want to use for trading\n",
    "joblib.dump(log_model, 'log_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Implement the strongest model using Apaca API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Develop the Algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Use the provided code to ping the Alpaca API and create the DataFrame needed to feed data into the model.\n",
    "   * This code will also store the correct feature data in `X` for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the list of tickers\n",
    "\n",
    "ticker_list = ['FB','AMZN','AAPL','NFLX', 'GOOGL', 'MSFT', 'TSLA']\n",
    "# Define Dates\n",
    "\n",
    "beg_date = '2021-01-06'\n",
    "end_date = '2021-01-06'\n",
    "\n",
    "# Convert the date in a format the Alpaca API reqires\n",
    "start =  pd.Timestamp(f'{beg_date} 09:30:00-0400', tz='America/New_York').replace(hour=9, minute=30, second=0).astimezone('GMT').isoformat()[:-6]+'Z'\n",
    "end   =  pd.Timestamp(f'{end_date} 16:00:00-0400', tz='America/New_York').replace(hour=15, minute=0, second=0).astimezone('GMT').isoformat()[:-6]+'Z'\n",
    "timeframe='1Min'\n",
    "\n",
    "# Use iloc to get the last 10 mins every time we pull new data\n",
    "prices = api.get_barset(ticker_list, \"minute\", start=start, end=end).df.iloc[-11:]\n",
    "prices.ffill(inplace=True)   \n",
    "\n",
    "# Create an empty DataFrame for closing prices\n",
    "df_closing_prices = pd.DataFrame()\n",
    "\n",
    "# Fetch the closing prices of our tickers\n",
    "df_closing_prices[\"FB\"] = prices[\"FB\"][\"close\"]\n",
    "df_closing_prices[\"AMZN\"] = prices[\"AMZN\"][\"close\"]\n",
    "df_closing_prices[\"AAPL\"] = prices[\"AAPL\"][\"close\"]\n",
    "df_closing_prices[\"NFLX\"] = prices[\"NFLX\"][\"close\"]\n",
    "df_closing_prices[\"GOOGL\"] = prices[\"GOOGL\"][\"close\"]\n",
    "df_closing_prices['MSFT'] = prices['MSFT'][\"close\"]\n",
    "df_closing_prices['TSLA'] = prices['TSLA'][\"close\"]\n",
    "\n",
    "print(df_closing_prices.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of momentums\n",
    "list_of_momentums = [1,5,10]\n",
    "\n",
    "for i in list_of_momentums:  \n",
    "    # Compute percentage change for each one of the momentums in the momentum list\n",
    "    returns_temp = df_closing_prices.pct_change(i)\n",
    "    # Unstack the returns \n",
    "    returns_temp = pd.DataFrame(returns_temp.unstack())\n",
    "    name = f'{i}_m_returns'\n",
    "    returns_temp.rename(columns={0: name}, inplace = True)\n",
    "    # Reset the index so we can merge based on index\n",
    "    returns_temp.reset_index(inplace = True)\n",
    "    # Merge newly computed returns with previously created returns\n",
    "    if i ==1:\n",
    "        returns = returns_temp\n",
    "    else:\n",
    "        returns = pd.merge(returns,returns_temp,left_on=['level_0', 'time'],right_on=['level_0', 'time'], how='left', suffixes=('_original', 'right'))\n",
    "\n",
    "# Drop nulls and set index\n",
    "returns.dropna(axis=0, how='any', inplace=True)\n",
    "returns.set_index(['level_0', 'time'], inplace=True)\n",
    "\n",
    "# Generate feature data and preview first 10 rows.\n",
    "X = returns\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Using `joblib`, load the chosen model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the previously trained and saved model using joblib\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Use the model file to make predicttions:\n",
    "* Use `predict` on `X` and save this as `y_pred`.\n",
    "* Convert `y_pred` to a DataFrame, setting the index to the index of `X`.\n",
    "* Rename the column 0 to 'buy', be sure to set `inplace =True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model file to predict on X\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Convert y_pred to a dataframe, set the index to the index of X\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Rename the column 0 to 'buy', be sure to set inplace =True\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Filter the stocks where 'buy' is equal to 1, saving the filter as `y_pred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the stocks where 'buy' is equal to 1\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Using the `y_pred` filter, create a dictionary called `buy_dict` and assign 'n' to each Ticker (key value) as a placeholder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary from y_pred and assign a 'n' to each of them for now as a placeholder.\n",
    "buy_dict = dict.fromkeys(y_pred.index.get_level_values(0), 'n')\n",
    "buy_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Obtain the total available equity in your account from the Alpaca API and store in a variable called `total_capital`. You will split the capital equally between all selected stocks per the CIO's request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull the total available equity in our account from the  Alpaca API\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute capital per stock, divide equity in account by number of stocks\n",
    "# Use Alpaca API to pull the equity in the account\n",
    "if len(buy_dict) > 0:\n",
    "    capital_per_stock = float(total_capital)/ len(buy_dict)\n",
    "else:\n",
    "    capital_per_stock = 0\n",
    "print(f'Capital per stock: {capital_per_stock}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Use a for-loop to iterate through `buy_dict` to determine the number stocks you need to buy for each ticker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use for loop to iterate through dictionary of buys \n",
    "# Determine the number stocks we need to buy for each ticker\n",
    "for ticker in buy_dict:\n",
    "    try:\n",
    "        buy_dict[ticker] = int(capital_per_stock /int(prices[ticker].iloc[-1]['close']))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(buy_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Cancel all previous orders in the Alpaca API (so you don't buy more than intended) and sell all currently held stocks to close all positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cancel all previous orders in the Alpaca API\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Sell all currently held stocks to close all positions\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Iterate through `buy_dict` and send a buy order for each ticker with their corresponding number of shares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the longlist object and send a buy order for each ticker with a corresponding number of shares:\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automate the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Make a function called `trade()` that incorporates all of the steps above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all of the steps conducted above into the function trade\n",
    "def trade():\n",
    "\n",
    "    ticker_list = ['FB','AMZN','AAPL','NFLX', 'GOOGL', 'MSFT', 'TSLA']\n",
    "    # Notice that we remove the start and end variables since we want the latest prices.\n",
    "    timeframe='1Min'\n",
    "    # Use iloc to get the last 10 mins every time we pull new data\n",
    "    prices = api.get_barset(ticker_list, \"minute\").df.iloc[-11:]\n",
    "    prices.ffill(inplace=True)   \n",
    "\n",
    "    # Create and empty DataFrame for closing prices\n",
    "    df_closing_prices = pd.DataFrame()\n",
    "\n",
    "    # Fetch the closing prices of our tickers\n",
    "    df_closing_prices[\"FB\"] = prices[\"FB\"][\"close\"]\n",
    "    df_closing_prices[\"AMZN\"] = prices[\"AMZN\"][\"close\"]\n",
    "    df_closing_prices[\"AAPL\"] = prices[\"AAPL\"][\"close\"]\n",
    "    df_closing_prices[\"NFLX\"] = prices[\"NFLX\"][\"close\"]\n",
    "    df_closing_prices[\"GOOGL\"] = prices[\"GOOGL\"][\"close\"]\n",
    "    df_closing_prices['MSFT'] = prices['MSFT'][\"close\"]\n",
    "    df_closing_prices['TSLA'] = prices['TSLA'][\"close\"]\n",
    "    print(df_closing_prices.head())\n",
    "    \n",
    "    # Loop through momentums to build new DataFrame\n",
    "    list_of_momentums = [1,5,10]\n",
    "    for i in list_of_momentums:   \n",
    "        returns_temp = df_closing_prices.pct_change(i)\n",
    "        returns_temp = pd.DataFrame(returns_temp.unstack())\n",
    "        name = f'{i}_m_returns'\n",
    "        returns_temp.rename(columns={0: name}, inplace = True)\n",
    "        returns_temp.reset_index(inplace = True)\n",
    "        if i ==1:\n",
    "            returns = returns_temp\n",
    "        else:\n",
    "            returns = pd.merge(returns,returns_temp,left_on=['level_0', 'time'],right_on=['level_0', 'time'], how='left', suffixes=('_original', 'right'))\n",
    "\n",
    "    # Drop nulls and set index            \n",
    "    returns.dropna(axis=0, how='any', inplace=True)\n",
    "    returns.set_index(['level_0', 'time'], inplace=True)\n",
    "\n",
    "    # Preprocess data for model\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # Create the `buy_dict` object\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # Split capital between stocks and determine buy or sell\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    \n",
    "    # Cancel pending orders and close positions\n",
    "    # YOUR CODE HERE\n",
    "   \n",
    "    \n",
    "    # Submit orders\n",
    "    # YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Import Python's schedule module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python's schedule module \n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Use the \"schedule\" module to automate the algorithm:\n",
    "* Clear the schedule with `.clear()`.\n",
    "* Define a schedule to run the trade function every minute at 5 seconds past the minute mark (e.g. `10:31:05`).\n",
    "* Use the Alpaca API to check whether the market is open.\n",
    "* Use run_pending() function inside schedule to execute the schedule you defined while the market is open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the schedule\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Define a schedule to run the trade function every minute at 5 seconds past the minute mark (e.g. 10:31:05)\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Use the Alpaca API to check whether the market is open\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Use run_pending() function inside schedule to execute the schedule you defined as long as the market is open\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "405d1f8999b38946e1a55ed7b4fbc22e3337bc0e954c12e008e73265e3b737b3"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('algotrading')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
